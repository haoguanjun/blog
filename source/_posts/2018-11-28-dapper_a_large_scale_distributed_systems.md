---
date: 2018-11-28
title: 大规模分布式系统追踪基础设施
categories: opentracing
---
现代Internet服务通常被实现为复杂的大规模分布式系统。这些应用来自于多个不同团队开发的软件模块，这些模块也许使用了不同的编程语言，分布在多个物理机房的上千台机器之中。在这样的环境下，帮助理解系统的表现和论证关于效率的问题的工具是无价的。

这里我介绍了Dapper的设计——Google的分布式系统trace基础设施，然后描述了我们低开销、应用级透明、在大规模系统上无处不在地部署的设计目标是如何实现的。Dapper与其他追踪系统在概念上是相同的，尤其是Magpie和X-Trace，但是我们所做出的设计选择是在我们环境中成功的关键，例如抽样的使用和限制instrumentation为非常小的通用库。
<!-- more -->

# Dapper：大规模分布式系统追踪基础设施

本文为Dapper, a Large-Scale Distributed Systems Tracing Infrastructure论文的翻译



## 摘要
现代Internet服务通常被实现为复杂的大规模分布式系统。这些应用来自于多个不同团队开发的软件模块，这些模块也许使用了不同的编程语言，分布在多个物理机房的上千台机器之中。在这样的环境下，帮助理解系统的表现和论证关于效率的问题的工具是无价的。

这里我介绍了Dapper的设计——Google的分布式系统trace基础设施，然后描述了我们低开销、应用级透明、在大规模系统上无处不在地部署的设计目标是如何实现的。Dapper与其他追踪系统在概念上是相同的，尤其是Magpie和X-Trace，但是我们所做出的设计选择是在我们环境中成功的关键，例如抽样的使用和限制instrumentation为非常小的通用库。

这篇论文的主要目标是去报告建立、部署和使用该系统的两年经验，因为Dapper的最重要的成功标准是它对开发人员和运维有价值。Dapper开始作为一个独立的trace工具，但是演化成了一个可以使用很多不同工具的监控平台，有些工具没有被设计者参预想出来。我们会描述一些用Dapper构建的分析工具、分享在Google内部的使用统计数据、给出一些使用样例，然后讨论迄今为止吸取的经验教训。

## 1 介绍
我们开发Dapper是为了给Google的开发人员提供更多的关于复杂分布式系统的行为信息。这样的系统有一个特殊的好处，因为大量小型的服务器，作为Internet服务的载体，是一个高效的平台。在这个环境中理解系统的行为需要观察在很多不同的程序以及很多不同的机器之间的相关的活动。

一个Web查询的例子将会说明trace系统需要去解决的一些问题。一个前端服务可能会产生一个Web请求到上百个查询服务器，其中在每一个服务器上的查询都在它自己的索引内进行搜索。请求也有可能被发送到多个处理广告、检查拼写、或者寻找包含图像、音频、新闻等特殊结果的服务。来自这些服务的结果被有选择性地组合起来用于产生最终的页面；我们称这个模型为“universal search”[6]。总共可能需要上千台服务器和很多不同的服务去处理“universal search”请求。还有，用户对于延迟是敏感的，子系统的低效都可能导致总体性能较低。工程师仅仅看一眼总体的延迟就可能知道出现故障了，但是不可能猜出哪个服务出了故障，也不能解释这种行为表现。首先，工程师可能不会准确地意识到正在使用哪一个服务；新服务每周都会出现，旧服务每周都会被改动，这些情况都会添加一些用户可见的特性或提升性能、安全方面的东西。第二，工程师不会精通每一个服务的内部原理；每一个服务由不同的团队开发和维护。第三，服务可能同时被很多种不同的客户端使用，所以服务的性能可能取决于其他客户端的行为。举个例子，一个前端服务可能要应付各种各样的请求类型，而一个使用效率很高的存储系统，比如Bigtable，有可能正被反复读写着，因为上面跑着各种各样的应用。

上面所讨论的案例为Dapper引出了两个基本条件：无处不在的部署和持续监控。无处不在的部署是很重要的条件，因为如果系统的一小部分没有被监控，trace基础设施的可用性可以被严重的影响。另外，监控应该总被开启，因为通常情况下异常的或其他值得注意的系统行为很难重现甚至不可重现。从这两个条件中推导出了三个具体的设计目标：

* 低开销：trace系统对运行的服务的性能影响应该忽略不计。在某些高度优化的服务中，甚至一点小的监控开销都很容易察觉到，这样可能会迫使开发团队把trace系统关闭掉。
* 应用级透明：开发人员不应需要意识到trace系统的存在。依赖于开发人员积极协作以实现运作的trace基础设施是非常脆弱的，由于trace库的漏洞或疏忽它经常坏掉，因此违反了无处不在的要求。像我们这样，对于快节奏的开发环境尤为重要。
* 可扩展性：它至少需要在未来几年处理Google服务和群集的规模。
一个额外的设计目标是trace数据在被生成之后可以在一分钟之内获得用于快速分析。虽然trace分析系统处理旧的数据仍然很有价值，但是新数据的获取可以更快感知到异常。

真正的应用级透明可能是我们最富有挑战的目标，这个目标的实现是通过约束Dapper核心追踪代码小巧玲珑，然后把它植入到线程库、控制流和RPC库代码中。系统的可扩展性和减少性能开销由自适应抽样来完成，这将会在4.4节描述。最终所产生的trace系统也会包含收集trace的代码、可视化工具和分析大量trace数据的库。虽然Dapper本身足够开发人员去寻找性能异常的根源，但它并不打算代替其他工具。我们发现Dapper的数据通常用于性能分析，所以其他的工具也有各自的用处。

### 1.1 贡献摘要
分布式系统追踪工具的设计空间已经在许多优秀的文章中被探索过，其中包括最接近Dapper的是Pinpoint[9]，Magpie[3]，和X-Trace[12]。这些系统在有机会清晰地计算重要设计选择之前，在其研究文献中很早就有描述。自从Dapper在生产和大规模环境中使用了几年，我们认为将本文重点放在设计决策是如何实现的，以及它最有用的方面是什么？Dapper作为性能分析工具的开发平台与自身监控的价值一样多。

虽然Dapper与Pinpoint和Magpie有很多相似的想法，但是在这个领域中我们的实现包含了一些新的贡献。例如，我们发现对于低开销抽样是必要的，尤其是在高度优化的延迟敏感的Web服务。也许令人惊奇的是，我们发现只对千分之一的请求进行抽样就可以为追踪数据常见用法提供够多的信息。

我们这个系统的其他重要特性是我们事先的应用级透明的程度。我们的instrumentation被限制为足够低的软件栈，即使像Google那样的web搜索也可以不需要额外的注解就能被追踪。虽然这很容易实现，因为我们的部署环境具有一定的同质性，我们的结果证明了实现这种透明度的一些充分条件。



## 2 在Dapper中进行分布式追踪
分布式服务的追踪基础设施需要记录关于在系统中代表请求发起者的所有完成的工作的信息。例如，图1说明了一个包含有五个服务器的服务：前端服务（A），两个中间层（B和C），和两个后端服务（D和E）。当一个用户请求（在这个例子中就是发起者）到达前端服务，它发送两个RPC请求到服务B和C。B可以立即返回回复，但是C在返回回复之前需要对D和E进行请求，在这完成之后才会把回复返回给用户。对于这个请求，一个简单但是有用的分布式追踪是在每一个服务器上面收集发送和接收的带有消息标识和时间戳的事件。

有两类解决方案已经被提出来去聚合这样的信息，黑盒和基于注解的监控方案，这样只要指定一个发起者（e.g.，图一中的RequestX）人们就可以关联起所有的记录实体。黑盒方案[1,15,2]假设记录实体中没有其他额外的信息，只有消息的记录，使用统计回归技术去推断他们之间的关系。基于注解的机制[3,12,9,16]依赖于应用和中间件明确地给每一个记录关联一个全局标识符用于定位请求者。黑盒机制比基于注解的机制更可移植，但是由于依赖统计推断，需要更多的数据去获得足够精确的结果。很明显，基于注解的方法最大的弊端是需要instrument。在我们的环境里，因为所有的应用使用相同的线程模型，控制流，和RPC，我们发现有可能限制instrumentation为通用库的小集合来实现对于应用开发者透明的监控系统。

我们倾向于将Dapper追踪视为嵌套的RPC树。然而，我们的核心数据并不约束为特定的RPC框架；我们也会追踪一些活动，列如Gmail中的SMTP会话，外部HTTP请求，SQL请求。从形式上来看，我们使用tree，spans，annotations为Dapper建模。



### 2.1 追踪trees和spans
在Dapper追踪树中，树节点是基本的工作单位，称之为span。树的边指明了一个span和它父span之间的关系。不管span在追踪trees的位置如何，一个span总是一个带有时间戳信息的记录的简单日志，它包含了span的开始时间和结束时间，RPC的时序数据，和另个或多个特定于应用的注解，正如2.3节讨论的那样。

我们来解释一下spans是如何形成像图2那样的追踪结构。Dapper为了重建单独的span之间的关系，它为每个span记录了可读的span名字，和span ID以及父ID。没有父ID的span被称为根span。与某一个trace相关联的span全部共享同一个traceID。这些ID为64bit的整数。在典型的Dapper追踪中，我们期望为每一个RPC去寻找一个单一的span，并且每个额外的基础设施都会增加追踪树的深度。

图三提供了一个在典型追踪span中记录的事件。这特定的span描述了在图二中两个“Helper.Call”RPC中较长的一个。Span开始和结束时间就像任何RPC时序信息一样被Dapper的RPC库记录。如果应用owner选择去添加自己的注解（就像图中的“foo”），这些也会被记录在span数据中。

需要注意的是一个span可以包含来自多个主机的信息；事实上每个RPCspan包含来自客户端和服务端进程的注解。因为在客户端和服务端上的时间戳来自不同的机器，我们需要小心时钟便宜。在我们的分析工具中，我们利用了这样的一个事实，一个RPC客户端总是在一个服务器接收到请求之前发送请求。这样，我们就有了一个span的时间戳的下界和上界。



### 2.2 instrumentation point

Dapper通过依赖几乎整个通用库，能够服从分布式控制路径，几乎不受开发人员的干预：

* 当一个线程处理被追踪的控制路径时，Dapper在线程局部存储中附带一个追踪上下文。一个追踪上下文是一个小的容易复制的span属性的容器，例如span id和追踪id。
* 当计算被推迟或者是异步调用，大多数Google开发者使用通用控制流库区构建回调，在线程池或其他执行器中调度它们。Dapper确保所有这样的回调存储了创建者的追踪上下文，当回调被调用时这个追踪上下文与合适的线程关联起来。通过这种方法，Dapper Id用于重新构建追踪，这样就可以满足异步控制路径透明。
* 几乎所有Google的进程间通信都围绕着一个使用c++和java的RPC框架构建的。我们在框架中为所有RPC定义了span。为了追中tpc，span和追踪id会从客户端发送到服务端。对于基于RPC的系统，就像在Google大范围使用的那样，是一个主要的点。我们计划去为非RPC通信框架增加追踪。
Dapper追踪数据是独立于语言的，很多在生产环境中的追踪结合了来自c++和Java的进程。在3.2节，我们讨论我们可以在实践中实现的应用透明级。



### 2.3 注解
在上面描述的 instrumentation points足够推倒出复杂的分布式追踪系统的细节，使核心的Dapper功能可用于未经修改的Google应用程序。然而，Dapper也允许应用开发者去增添Dapper一些额外的信息，这些信息可能对于监控更高层次的系统表现或是对调试问题有所帮助。我们允许用户通过简单API去使用带有时间戳的注解，核心如图4。这些注解可以有任意的内容。为了去保护Dapper用户免受过多的记录注解，单个追踪span在注解总量上是可以配置的。应用级注解无法替代span或RPC信息。

除了简单地文本注解，Dapper还支持了键值对注解是的追踪更强大，例如维护计数器，记录仪二进制消息，在进程中传输任意用户定义的数据。

### 2.4 抽样
低开销是Dapper的关键设计，因为服务操作人员情有可原地不愿使用如果对性能有影响的未经正证实有价值的新工具。还有，我们希望可以让开发人员在使用注解API时不必害怕额外的开销。我们还发现某类Web服务对于基础库是很敏感的。因此，我们尽可能地使Dapper基础库的开销低，我们对所有的追踪进行抽样进一步控制开销。我们在4.4节中进一步描述抽样机制的细节。

### 2.5 追踪收集
Dapper追踪记录和收集管道是一个三阶段的过程（见图五）。首先，span数据写进本地日志文件。然后它被在生产环境中的Dapper基础设施拉取，最终被写进Bigtable[8]。一个trace成为Bigtable中的一行。bigtable支持的稀疏表格布局在这里是很有用的，因为单独的trace可以有任意数量的span。中等延迟的数据收集时间，也就是说数据从应用程序到中心存储库小于15秒。

Dapper也提供了一个API区简化trace数据的访问。在Google的开发者使用这个API区构建通用目的和应用具体的分析工具。5.1节包含了更多关于使用的信息。

#### 2.5.1 带外数据收集
所描述的Dapper系统通过请求树本身进行带外记录和带外收集。这是出于两个不相关的原因。首先，带内收集机制-追踪数据被RPC回复头部返回-可以影响应用网络动态。在Google中的许多大规模系统，可以很容易找到具有上千span的追踪。但是，RPC响应 - 即使接近这种大型分布式追踪的根源 - 仍然可能比较小：通常少于10KB。在这些情况下，带内Dapper跟踪数据会使应用程序数据变小并偏移后续分析的结果。第二点，带内收集机制假设所有RPC是完美嵌套的。我们发现有很多中间件系统在所有他们后端服务返回最终结果之前就返回给调用者结果。带内收集系统无法解释这种非嵌套的分布式执行模式。

### 2.6 安全和隐私考量
记录一些数量的RPC负荷信息将会丰富Dapper追踪因为分析工具可以发现负荷数据中的模式，这些模式可能可以解释性能异常的原因。然而，这里有很多其他情况，有效载荷数据可能包含不应向未经授权的内部用户公开的信息，包括性能调试信息。

由于安全和隐私问题是不可协商的，Dapper存储RPC方法的名字但是目前不记录任何负荷数据。相反，应用级注解提供了方便的可选的机制：应用开发人员可以选择去任何认为对后续分析有用的数据与span关联起来。

Dapper还提供了一些安全性优势，这是设计者所没有预见的。例如，通过追踪公共安全协议参数，Dapper通过合适的授权或加密级别用于监控应用是否满足安全策略。Dapper还可以提供信息以确保系统的基于策略的隔离按预期执行，例如， 那些包含敏感数据的应用程序不会与未经授权的系统组件进行交互。 这些形式的测量比源代码审计提供了更大的保证。

## 3 Dapper部署状态
Dapper在生产环境中已经使用了两年。在这一节中，我们会抱够这个系统的状态，专注于它是如何满足我们无处不在的部署和应用级透明的目标的。

### 3.1 Dapper运行时库
也许Dapper代码最关键的部分是RPC，线程和控制流库，他们包括了span创建，抽样和记录到磁盘。除了轻便之外，这个代码需要稳定和鲁棒因为它被连接进很多应用，使维护和漏洞修正很难。核心代码在c++中小于1000行，在java中小于800行。键值注解增加了额外的500行代码。

### 3.2 生产覆盖
Dapper的渗透可以从两个方面进行评估：可以生产Dapper追踪（链接到Dapper库的进程）的生产环境的进程和运行Dapper追踪收集进程的生产环境的机器的占比。Dapper进程是我们基础机器镜像的一部分，几乎在谷歌的每一台服务器上都有它。由于不生成跟踪信息的进程对Dapper来说是不可见的，因此很难确定精确的比例。然而，考虑到无处不在的Dapper工具库，我们估计几乎所有的Google生产进程都支持跟踪。

有Dapper无法正确地遵循控制路径的情况。典型的根源来源于非标准控制流原语，或者当Dapper错误地将因果关系归因于不相关的事件时。Dapper提供一个简单的库作为解决方法来帮助开发人员手动地控制trace传播。目前这里有40个C++应用和33个Java应用需要手动地传播trace，只占非常小的一部分。还有非常少的程序使用了没有trace的通讯库（原始TPC套接字，或SOAP RPC），因此并不支持Dapper追踪。如果trace被认为是重要的，Dapper可以为这些库添加trace。

作为安全生产措施，Dapper追踪可以被关闭。事实上在Dapper早期，追踪是默认关闭的，直到我们对它的稳定性和低开销有信心。Dapper团队偶尔会审计对追踪的关闭。这样的情况非常少，通常是顾虑监控的开销。迄今为止所有这些对追踪的关闭的情况都是在对实际开销进行进一步调查和衡量后得到恢复的。

### 3.3 追踪注解的使用
程序员倾向于将特定于应用程序的注释用作一种分布式调试日志文件，或者通过某些特定于应用程序的功能对trace进行分类。比如，所有Bigtable请求被注解为被访问的表的名字。当前，70%的span和90%的trace至少有一个特定于应用的注解。



## 4 管理追踪开销
追踪系统的开销会因为感觉是由于追踪的生成和收集的开销两者而导致系统的性能下降。虽然人们可以争论有价值的追踪基础设施有一些性能损失也是值得的，我们认为，如果基准线开销可以被忽略，那么最初的采用将很方便。

在这一节中，我们给出了主要Dapper操作的开销，追踪收集的开销，和对生产环境工作负载的影响。我们也描述了Dapper自适应追踪采样机制是如何帮助我们平衡低负荷和表示追踪的需要的。

### 4.1 追踪生成开销
追踪生成开销是Dapper性能中最中要的，因为手机和分析可以在紧急情况下被关闭。在Dapper通用库的追踪生成开销的最重要的源码是创建和销毁span和注解，然后为了后续收集，把他们记录到磁盘。根span的创建和销毁平均花费204纳秒，然而同样的操作在非根span上需要176纳秒。他们两者之间的差异是因为需要为根span生成独一无二的全局traceID。

如果span没有被抽样，在Dapper运行时内部包含线程局部数据的查找，平均每次操作花费9纳秒，额外的span注解开销是最不可忽视的。如果被抽样了，注解一个字符串字面量，就像图4那样，平均花费40纳秒。这些测量发生在2.2GHZ x86服务器上。

写本地磁盘是在Dapper运行时库中最昂贵的操作，但是可见的开销被减小了因为磁盘会聚和多个日志文件写操作，相对于跟踪的应用程序异步地执行。然而，日志写活动会对高吞吐量有应用的性能有显著的影响，尤其是所有请求都会被追踪。我们在4.3节中量化Web搜索的开销。



### 4.2 追踪收集开销
读出本地追踪数据也会干扰正在监视的前台工作的负载。表一展示了Dapper进程基于不现实的高负载测试基准的CPU使用率最坏的情况。Dapper进程在收集的时候只占不到生产环境机器0.3%的CPU利用率，和很少的内存。我们也限制了Dapper进程在内核中的调度为最低的优先级来防止在高负载机器下CPU竞争的出现。

Dapper也是网络资源的消费者，每一个span平均来说对应于426字节。在我们正在监控的应用程序中，作为网络活动的一小部分，Dapper追踪数据收集占用的网络带宽不到在Google生产环境中网络流量的0.01％。

### 4.3 生产环境中负载的影响
对每一个请求都利用到大量的机器的高吞吐量在线服务最需要高效地追踪；它们会生产大量的追踪数据，同时它们也是对性能干扰最为敏感的。在表二中，我们使用Web搜索集群作为一个这样的服务的例子。我们测量了Dapper对平均延迟和吞吐量的性能影响，因为我们改变了Dapper的抽样率。

我们看到虽然对吞吐量的影响并不显著，为了避免明显的延迟增加，追踪抽样确实是必须的。然而，采样频率小于1/16相关的延迟和吞吐量损失都在实验误差之内。在实践中，当抽样率低于1/1024时，我们发现对于高负载的服务仍然有足够多的追踪数据。使Dapper开销非常低是很重要的，因为它给使用注释API的应用程序带来一些松懈，而不用担心性能会受到影响。使用较低的采样频率具有额外的好处，即允许数据在被垃圾收集之前在主机的本地磁盘上持续较长时间，这为收集基础设施提供了更大的灵活性。

### 4.4 自适应抽样
Dapper开销与每单位时间处理采样的跟踪数量成正比。第一个生产版本的Dapper在Google的所有进程中使用统一的采样率，平均每1024个span采样一次。这个简单的方案对于我们的高吞吐量在线服务是有效的，因为绝大多数感兴趣的事件仍然很可能经常出现足以被捕获。但是，流量较低的工作负载可能会以如此低的采样率丢失重要的事件，同时容忍更高的采样率和可接受的性能开销。 这种系统的解决方案是重写默认采样率，这是我们在Dapper中试图避免的那种手动干预。我们正在部署一种自适应采样方案，该方案不是通过统一的采样概率进行参数化，而是通过每单位时间追踪的期望采样率进行参数化。 这样，流量较低的工作负载会自动提高采样率，而流量较大的工作负载会降低采样率，从而使开销得到控制。 使用的实际采样概率与跟踪本身一起记录; 这有助于准确计算围绕Dapper数据而建立的分析工具中的追踪频率。

### 4.5 应对积极的抽样
新的Dapper用户常常想知道低采样概率 - 对于高流量服务通常低至0.01％是否会干扰他们的分析。在Google的经验告诉我们，对于高吞吐量的服务，积极采样不会妨碍最重要的分析。如果一个显著的执行模式在这样的系统中出现一次，它将会出现数千次。负载较低的服务，几十QPS的请求，可以对每一个请求进行追踪。这促使我们决定走向自适应采样率。

### 4.6 收集期间的额外的抽样
上述采样机制旨在最大限度地减少包含Dapper运行时库的应用程序中的可感知的开销。 尽管如此，Dapper团队还需要控制写入中心化存储的数据的大小，因此我们为此目的包含第二轮采样。

我们的生产集群目前每天生成超过1TB的追踪采样数据。 Dapper用户希望追踪数据在从最初生产过程记录后至少保留两周的时间。 然后，必须权衡增加的追踪数据密度的好处与Dapper存储的机器和磁盘存储的成本。 对大部分请求进行采样还会使Dapper接近Bigtable写吞吐量的限制。

为了保持物质资源需求和Bigtable写入吞吐量的灵活性，我们在收集系统中增加了对其他采样的支持。我们面对这样一个事实，在特定的trace中，所有的span，虽然它们可能分布在上千台机器上，但只共享一个traceID。在收集系统中看见的每一个span，我们把traceID哈希为一个值z，0<=z<=1。如果z小于我们的抽样系数，我们保留这个span把它写进Bigtable中。否则，我们把这个span丢弃。通过取决于我们采样的traceID，我们可以采样或丢弃整个trace，而不是一个trace中的单个span。 我们发现这个额外的配置参数使得我们的收集管道的管理更加简单，因为我们可以通过更改一个在配置文件中的参数来轻松调整我们的全局写入速率。

如果整个跟踪和收集系统只有一个采样参数，则更简单，但在所有已部署的二进制文件中快速调整运行时采样配置是不可行的。 我们选择了一种运行时采样速率，其产生的数据略多于我们可以写入存储库的数据量，并且我们使用收集系统中的二次采样系数来限制写入速率。由于我们可以通过对二次采样配置进行单一更改而立即增加或减少我们的全局覆盖率和写入速率，因此Dapper维护更容易。

## 5 通用目的的Dapper工具
几年前，虽然Dapper仍然是原型，但它只有在Dapper开发人员的耐心协助下才能使用。从那以后，我们已经迭代构建了收集基础设施，编程接口和基于Web的交互式用户界面，以帮助Dapper用户独立解决问题。 在本节中，我们总结了哪些方法有效，哪些没有，并且提供了有关这些通用分析工具的基本使用信息。



### 5.1 Dapper API
Dapper API提供对区域Dapper存储库（或“仓库”）中分布式跟踪记录的直接访问。 DAPI和Dapper trace存储库是一体设计的，DAPI旨在为这些Dapper存储库中包含的原始数据提供干净，直观的接口。 我们的用例提出了以下三种访问trace数据的方式：

通过traceID访问：鉴于其全局唯一的traceID，DAPI可以根据需求加载任何trace。

批量访问：DAPI可以利用MapReduce来并行访问数十亿条trace。 用户重写一个虚拟函数，该函数接受一个trace作为其唯一参数，并且框架将为用户指定的时间窗口内的每个收集的trace调用该函数一次。

索引访问：Dapper存储库支持一个被选择的索引来匹配我们的通用访问模式。 该索引从通常需要的trace特征（如下所述）映射到不同的trace。 由于traceID是伪随机分配的，因此这是快速访问与特定服务或主机相关的trace的最佳方式。

所有这三种访问模式都会引导用户使用不同的trace记录。 如前面2.1节所述，trace被建模为span的树，因此Trace数据结构是一个简单的单个Span结构的可遍历的树。 span通常对应于RPC调用，并且在这些情况下，RPC时序信息可用。 应用程序注解也可以通过span结构访问。

选择合适的定制索引是DAPI设计中最具挑战性的方面。 索引trace数据所需的压缩存储比实际trace数据本身仅少26％，所以开销是很大的。我们最初使用了两个索引：主机的索引和服务名称的索引。 当用户对单个机器感兴趣时，他们也对特定的服务感兴趣，因此我们最终将这两者合并为一个组合索引，以便按服务名称，主机和时间戳进行高效查找。

### 5.2 Dapper用户界面
大多数Dapper使用情况发生在基于Web的交互式用户界面中。 空间考虑不允许我们展示其中的每一个特征，但是典型的用户工作流程如图6所示。

* 1：用户描述他们感兴趣的服务和时间窗口，以及他们需要区分trace模式的任何信息来（在本例中是跨度名称）。 他们还指定了与他们的调查最相关的成本指标（在这种情况下，服务延迟）。

* 2：出现与给定服务相关的所有分布式执行模式的大型表现摘要表。 用户可以按照他们的意愿对这些执行模式进行排序，并选择一个更详细地查看。

* 3：一旦选择单个分布式执行模式，就向用户呈现所述执行模式的图形描述。 正在检查的服务

在图的中心突出显示。

## 4：

## 5：

## 6 经验
Dapper在Google中广泛使用，既可以直接通过Dapper用户界面，也可以通过编程API或在这些API之上构建的应用程序间接使用。 在本节中，我们不试图对Dapper的每个已知用途进行编目，而是尝试覆盖Dapper用法的“基本向量”，以说明什么样的应用程序最成功。

### 6.1 在开发中使用Dapper
Google AdWords系统围绕关键字定位条件和相关文字广告的大型数据库构建。 当新的关键字或广告被插入或修改时，必须检查它们是否符合服务政策条款（如不适当的语言）; 一个由自动化审查系统提高效率的过程。

当需要从头开始重新设计Ads Review的一项服务时，该团队通过启动和最终维护系统，从第一个系统原型中反复使用Dapper。 Dapper通过以下方式帮助他们改进服务：

性能：开发人员根据请求延迟目标跟踪进度并确定简单的优化机会。 Dapper还被用于确定关键路径上的不必要的串行请求 - 通常来自开发人员自己编写的子系统 - 并促使团队随后修复它们。

正确性：广告查看服务围绕大型数据库系统展开。该系统具有只读副本（廉价访问）和读写主人（昂贵的访问）。 Dapper被用来识别一些不必要地向master服务器而不是副本发出查询的情况。现在可以考虑直接访问master并保证重要系统不变性的情况。

理解：广告评论查询涉及许多类型的系统，包括BigTable，上述数据库，多维索引服务以及各种其他C ++和Java后端服务。Dapper的trace被用来评估总查询成本，并促使重新设计操作，以尽量减少系统依赖关系的负载。

测试：新代码版本通过Dapper跟踪QA，验证正确的系统行为和性能。 使用此流程发现了许多问题，包括广告审核代码本身和支持库。

Ads Review团队广泛使用了Dapper注解API。 Guice [13]开源AOP框架用于将重要的软件组件标记为“@Traced”。trace进一步注解了有关输入和输出的大小的信息、状态消息和其他调试信息到重要子例程，否则被发送到日志文件。

在某些方面，Dapper对广告审核小组有不足之处。例如，他们希望在交互时间内搜索所有跟踪注释，但必须运行自定义MapReduce或手动检查单个跟踪。此外，Google还有其他系统可以收集和集中来自通用调试日志的信息，并且从这些系统和Dapper存储库中集成大量数据并非易事。

但总的来说，广告审核小组估计，使用从Dapper跟踪平台收集的数据，他们的延迟数量已经提高了两个数量级。



### 6.2 解决长延迟
由于部件的数量以及代码库和部署的规模和范围，调试诸如通用搜索之类的服务（在前面的第1节中描述）非常具有挑战性。 在这里，我们描述了减少通用搜索延迟分布所作出的努力。Dapper能够验证关于端到端延迟的假设，更具体地说，是统一搜索请求的关键路径。 当系统不仅涉及数十个子系统而且涉及数十个工程团队时，即使我们最优秀且经验最丰富的工程师也经常猜错端到端性能差的根本原因。 在这种情况下，Dapper可以提供非常需要的事实，并能够最终回答许多重要的表现问题。

一位致力于长尾延迟调试的工程师构建了一个小型库，可以从DAPI Trace对象中推断出分层关键路径。 然后，这些关键路径结构用于诊断问题，并优先考虑通用搜索的预期性能改进。 与Dapper的这项工作带来了以下发现：

沿着关键路径的网络性能的瞬间降级不会影响系统吞吐量，但它会对异常值延迟产生深远的影响。 如图7所示，大多数慢速通用搜索trace在其关键路径上经历了网络降级。
由于服务之间的意外交互，导致了许多有问题且昂贵的查询模式。 一旦确定，它们通常很容易纠正，但在Dapper之前识别本身很困难。
常见查询是从Dapper之外的安全日志存储库中获取的，并使用Dapper的唯一跟踪ID与Dapper存储库连接。 然后，该映射用于构建示例查询的列表，这些查询对于通用搜索中的每个单独子系统来说都很慢。
6.3 推断服务依赖
在任何时候，Google的典型计算集群都拥有数千个逻辑“工作”; 执行共同功能的一组过程。 当然，Google维护着许多这样的集群，事实上我们发现一个计算集群中的作业通常依赖于其他集群中的作业。 由于作业之间的依赖关系会动态变化，因此无法仅通过配置信息来推断所有服务间依赖关系。 尽管如此，公司内部的各种流程仍需要准确的服务依赖性信息，以便识别瓶颈并规划服务移动等。 谷歌恰当命名的“服务依赖项目”项目利用了跟踪注释和DAPI MapReduce接口，以自动化服务依赖性确定。

使用Dapper的核心工具以及Dapper跟踪注释，服务依赖项目能够推断各个作业之间的依赖关系，以及这些作业使用的共享软件基础结构的依赖关系。 例如，所有Bigtable操作都使用受影响的表的名称进行标记。 因此，使用Dapper平台，服务依赖关系团队能够在各种服务粒度下自动推断对命名资源的依赖性。

### 6.4 不同服务的网络使用情况
Google将大量的人力和物力资源用于其网络结构。 毫不奇怪，网络运营商长期以来可以从各个硬件中获取监控信息，并且构建了定制工具和仪表板，以便全面了解全局网络利用情况。 网络运营商对我们的广域网的整体健康状况有合理的可见性，但是，当出现问题时，他们几乎没有工具可以将网络负载正确归因于应用程序级别的罪魁祸首。

尽管Dapper不是为链路级监控而设计的，但我们发现它非常适合群集间网络活动的应用级分析任务。 谷歌能够利用Dapper平台构建一个持续更新的控制台，显示群集间网络流量最活跃的应用程序级端点。 此外，使用Dapper，我们能够指出这些昂贵的网络请求的因果跟踪根，而不是将我们自己限制在两个对等机器中。 仪表板是在不到两周的时间内在Dapper API之上构建的。

## 参考文献

- [Dapper, a Large-Scale Distributed Systems Tracing Infrastructure](https://ai.google/research/pubs/pub36356.pdf)
- [Dapper：大规模分布式系统追踪基础设施](https://zhuanlan.zhihu.com/p/38255020)